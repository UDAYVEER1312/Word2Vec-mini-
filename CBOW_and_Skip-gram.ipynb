{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "aa1aa12e-2e03-41b8-936c-568cc7397809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6f2b8263-40a0-4663-8d4b-c96074b4002b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['milk',\n",
       " 'is',\n",
       " 'used',\n",
       " 'in',\n",
       " 'making',\n",
       " 'bread',\n",
       " 'and',\n",
       " 'we',\n",
       " 'can',\n",
       " 'make',\n",
       " 'sandwich',\n",
       " 'from',\n",
       " 'bread']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Milk is used in making bread and we can make Sandwich from bread\"\n",
    "tokens = text.lower().split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a161418a-6470-4ea2-b806-be0bc62f9434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'milk': 0,\n",
       " 'is': 1,\n",
       " 'used': 2,\n",
       " 'in': 3,\n",
       " 'making': 4,\n",
       " 'bread': 5,\n",
       " 'and': 6,\n",
       " 'we': 7,\n",
       " 'can': 8,\n",
       " 'make': 9,\n",
       " 'sandwich': 10,\n",
       " 'from': 11}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = dict()\n",
    "for t in tokens:\n",
    "    if t not in vocab.keys():\n",
    "        vocab[t] = len(vocab)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1841949-76c3-4f1d-ab52-f3e554c6bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class w2vec(nn.Module):\n",
    "    def __init__(self,vocab, hidden):\n",
    "        super().__init__()\n",
    "        self.v = vocab\n",
    "        self.hidden_layer = nn.Linear(in_features = len(self.v), out_features = hidden) # weight matrix = input vectors W\n",
    "        self.out = nn.Linear(in_features = hidden, out_features = len(self.v))# weight matrix = output vectors W'\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    def get_input_vec(self,word):\n",
    "        with torch.no_grad():\n",
    "            return self.hidden_layer.weight.T[self.v[word]]\n",
    "    def get_output_vec(self,word):\n",
    "        with torch.no_grad():\n",
    "            return self.out.weight[self.v[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9def1970-c98c-4019-b912-27203fe065c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "cbow = w2vec(vocab,100)\n",
    "cbow.state_dict()['hidden_layer.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "456d4b61-e66b-44be-b904-6a7b679c4725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(word):\n",
    "    one_hot_vector = [0]*(len(vocab))\n",
    "    one_hot_vector[vocab[word]] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "099e3bcc-6874-4cc3-b848-2e52af63b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context(tokens,center,window_size=3):\n",
    "    start = center-window_size if center-window_size >0 else 0\n",
    "    end = center+window_size+1 if center+window_size+1 <= len(tokens) else len(tokens)\n",
    "    context = tokens[start : center] + tokens[center+1 if center+1 < len(tokens) else end : end]\n",
    "    # print(tokens)\n",
    "    # print(context)\n",
    "    return torch.tensor([one_hot_encoder(c) for c in context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0f6073d1-a1f5-44fa-877b-04ed3d89c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.SGD(params = cbow.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7222566d-331b-4364-9966-5e9f90315603",
   "metadata": {},
   "source": [
    "COW-MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6b7e8824-8104-4b78-8958-6c552ebed0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 | train_loss : 1.958733320236206\n",
      "Epoch : 20 | train_loss : 1.2391306161880493\n",
      "Epoch : 30 | train_loss : 0.6945803165435791\n",
      "Epoch : 40 | train_loss : 0.3786560297012329\n",
      "Epoch : 50 | train_loss : 0.22482378780841827\n",
      "Epoch : 60 | train_loss : 0.14783605933189392\n",
      "Epoch : 70 | train_loss : 0.10551529377698898\n",
      "Epoch : 80 | train_loss : 0.08004318922758102\n",
      "Epoch : 90 | train_loss : 0.0635107085108757\n",
      "Epoch : 100 | train_loss : 0.05211568623781204\n"
     ]
    }
   ],
   "source": [
    "# Create contexts and pass the suitable input\n",
    "epochs = 100\n",
    "cbow.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for center in range(len(tokens)):\n",
    "        context = generate_context(tokens, center = center, window_size = 2)\n",
    "        avg_input = torch.sum(context,dim=0)/len(context)\n",
    "        pred = cbow(avg_input)\n",
    "        loss = loss_fun(pred,torch.tensor(vocab[tokens[center]]))\n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer1.zero_grad()\n",
    "    if epoch % 10 == 9:\n",
    "        print(f\"Epoch : {epoch+1} | train_loss : {epoch_loss/len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47921237-c88a-49d2-9ccb-746830dcd082",
   "metadata": {},
   "source": [
    "SKIP-GRAM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "247c4d98-fb4d-4d83-b20b-7f65daf684ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "skip_gram = w2vec(vocab,100)\n",
    "skip_gram.state_dict()['hidden_layer.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fd2caf01-e7a5-4a6b-bce6-89be92626dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = torch.optim.SGD(params = skip_gram.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1a251c0d-b529-49af-90a1-1a04f1ea2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 | train_loss : 5.980834484100342\n",
      "Epoch : 40 | train_loss : 5.283209800720215\n",
      "Epoch : 60 | train_loss : 5.1318559646606445\n",
      "Epoch : 80 | train_loss : 5.074250221252441\n",
      "Epoch : 100 | train_loss : 5.043362617492676\n"
     ]
    }
   ],
   "source": [
    "# Create contexts and pass the suitable input_word\n",
    "epochs = 100\n",
    "skip_gram.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for center in range(len(tokens)):\n",
    "        context = generate_context(tokens, center = center, window_size = 2)\n",
    "        input_word = torch.tensor(one_hot_encoder(tokens[center]),dtype=torch.float)\n",
    "        preds = skip_gram(input_word)\n",
    "        stacked_preds = preds.repeat(len(context),1)\n",
    "        targets = torch.tensor([torch.argmax(c,dim=0) for c in context])\n",
    "        loss = loss_fun(stacked_preds,targets)\n",
    "        epoch_loss += loss*len(context)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        optimizer2.zero_grad()\n",
    "    if epoch % 20 == 19:\n",
    "        print(f\"Epoch : {epoch+1} | train_loss : {epoch_loss/len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7edfa4d8-28d0-44cf-8ccb-08b83b08c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1,vec2):\n",
    "    return torch.dot(vec1,vec2)/( (torch.norm(vec1) * torch.norm(vec2)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "39c02f8c-f46c-4651-8edc-4f73111c2ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between input and output vectors for CBOW\n",
      "milk :-0.04099941626191139\n",
      "is :-0.07781639695167542\n",
      "used :-0.23917976021766663\n",
      "in :-0.22917291522026062\n",
      "making :-0.22500504553318024\n",
      "bread :-0.43913477659225464\n",
      "and :-0.20420560240745544\n",
      "we :-0.12202194333076477\n",
      "can :-0.2393714189529419\n",
      "make :-0.20285667479038239\n",
      "sandwich :-0.4179246723651886\n",
      "from :-0.30360865592956543\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity between input and output vectors of a word\n",
    "print('Cosine similarity between input and output vectors for CBOW')\n",
    "for word in vocab.keys():\n",
    "    print(word,f\":{cosine_similarity(cbow.get_input_vec(word),cbow.get_output_vec(word) )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "79803cd4-2eef-46fc-a056-a4448d26fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between input and output vectors for SKIP-GRAM\n",
      "milk :0.05938509479165077\n",
      "is :0.06074342876672745\n",
      "used :-0.02561378665268421\n",
      "in :-0.12289121747016907\n",
      "making :-0.24847109615802765\n",
      "bread :-0.4889272451400757\n",
      "and :-0.19889748096466064\n",
      "we :-0.14856505393981934\n",
      "can :-0.11800306290388107\n",
      "make :-0.03872044011950493\n",
      "sandwich :-0.155063658952713\n",
      "from :-0.18093720078468323\n"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity between input and output vectors for SKIP-GRAM')\n",
    "for word in vocab.keys():\n",
    "    print(word,f\":{cosine_similarity(skip_gram.get_input_vec(word),skip_gram.get_output_vec(word) )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e566acdc-fb92-4439-8de7-7ebdef8f68d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between input vectors of both models\n",
      "milk :0.9849143028259277\n",
      "is :0.987615704536438\n",
      "used :0.9887687563896179\n",
      "in :0.9806521534919739\n",
      "making :0.9762115478515625\n",
      "bread :0.9834405183792114\n",
      "and :0.9898326396942139\n",
      "we :0.9847304224967957\n",
      "can :0.9677909016609192\n",
      "make :0.9707474112510681\n",
      "sandwich :0.9720782041549683\n",
      "from :0.9752551317214966\n"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity between input vectors of both models')\n",
    "for word in vocab.keys():\n",
    "    print(word,f\":{cosine_similarity(skip_gram.get_input_vec(word),cbow.get_input_vec(word) )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f5f71d6d-e4df-442e-a456-cfbacbf1d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between output vectors of both models\n",
      "milk :0.9645285606384277\n",
      "is :0.9757919907569885\n",
      "used :0.9560241103172302\n",
      "in :0.967519223690033\n",
      "making :0.981456458568573\n",
      "bread :0.9522157907485962\n",
      "and :0.9790166616439819\n",
      "we :0.962906002998352\n",
      "can :0.9760797619819641\n",
      "make :0.9437264800071716\n",
      "sandwich :0.9254117608070374\n",
      "from :0.9560730457305908\n"
     ]
    }
   ],
   "source": [
    "print('Cosine similarity between output vectors of both models')\n",
    "for word in vocab.keys():\n",
    "    print(word,f\":{cosine_similarity(skip_gram.get_output_vec(word),cbow.get_output_vec(word) )}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2acda211-58b8-480c-bda9-7d303917b538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5546, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milk = skip_gram.get_input_vec('milk')\n",
    "bread = skip_gram.get_input_vec('bread')\n",
    "sandwich = skip_gram.get_input_vec('sandwich')\n",
    "we = skip_gram.get_input_vec('we')\n",
    "make = skip_gram.get_input_vec('make')\n",
    "making = skip_gram.get_input_vec('making')\n",
    "_is = skip_gram.get_input_vec('is')\n",
    "_in = skip_gram.get_input_vec('in')\n",
    "milk_bread = milk + bread\n",
    "cosine_similarity(milk_bread,bread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "451fa09a-1f8a-46a3-9e35-2cff06393b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0667, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(_is,_in)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
